<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Random Notes!</title>
    <link>https://azmfaridee.github.io/</link>
    <description>Recent content on Random Notes!</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 14 Oct 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://azmfaridee.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Transfer Learning Notes</title>
      <link>https://azmfaridee.github.io/post/2020/10/14/transfer-learning/</link>
      <pubDate>Wed, 14 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://azmfaridee.github.io/post/2020/10/14/transfer-learning/</guid>
      <description>Label, Domain and Tasks: A Definition A domain $\mathbb{D}$ consists of:
 a feature space $\mathscr{X}$ and a marginal probability distribution $\mathbb{P}^X$, where each input instance $x \in \mathscr{X}$.  Two domains are different when they have different feature space or different marginal probability distributions. Given a specific domain $\mathbb{D} = \{\mathscr{X}, \mathbb{P}^X\}$, a task, $\mathbb{T}$ consists of two components:
 a label space $\mathscr{Y}$ and a function $f(\cdot)$.  Therefore, $\mathbb{T} = \{\mathscr{Y}, f(\cdot)\}$.</description>
    </item>
    
    <item>
      <title>About Me</title>
      <link>https://azmfaridee.github.io/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://azmfaridee.github.io/about/</guid>
      <description>I&amp;rsquo;m a 5th year Ph.D. student at the Informations Systems Department at the University of Maryland, Baltimore County. I work with Dr. Nirmalya Roy in the Mobile, Pervasive, and Sensor Computing (MPSC) Lab.
My research is focused on building scalable machine learning models that are robust against domain and category shifts with minimal-to-no extra label information. To that end, I primarily work on deep unsupervised, self-supervised, adversarial representation learning &amp;amp; learnable data augmentation techniques.</description>
    </item>
    
  </channel>
</rss>
